{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1881dcf1",
   "metadata": {},
   "source": [
    "## Given 6 days, on day one you had rice, day two you had beans, day three you had eggs, day four you had cakes, day five you had soup, and day six you had fruits.\n",
    "## 1a. repesent this data in python using the correct data structure/type. 1b. use this data to create a pandas series. 1c. display the series from fourth day to the last day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "196ce114",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'day 1': 'rice', 'day 2': 'beans', 'day 3': 'eggs', 'day 4': 'cakes', 'day 5': 'soup', 'day 6': 'fruits'}\n"
     ]
    }
   ],
   "source": [
    "meals={\n",
    "                    \"day 1\":\"rice\",\n",
    "                    \"day 2\": \"beans\",\n",
    "                    \"day 3\": \"eggs\",\n",
    "                    \"day 4\":\"cakes\",\n",
    "                    \"day 5\": \"soup\",\n",
    "                    \"day 6\": \"fruits\",\n",
    "                }\n",
    "print(meals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6ba336cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b1c74d1a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "day 1      rice\n",
      "day 2     beans\n",
      "day 3      eggs\n",
      "day 4     cakes\n",
      "day 5      soup\n",
      "day 6    fruits\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "info = pd.Series(meals)\n",
    "print(info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2d66035c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "day 4     cakes\n",
      "day 5      soup\n",
      "day 6    fruits\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(info[3:])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3cce6a0",
   "metadata": {},
   "source": [
    "## 2a. create two arrays of random number between 1 and 4 with a length of 10 values 2b. use both arrays to create a pandas series 2c. perform the following arithmetic operations on both arrays using addition, multiplication, division and subtraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fdd65526",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2 2 1 3 1 1 1 1 2 1]\n",
      "[1 3 2 1 3 2 1 2 3 3]\n"
     ]
    }
   ],
   "source": [
    "arr1=np.random.randint(1,4,10)\n",
    "arr2=np.random.randint(1,4,10)\n",
    "print(arr1)\n",
    "print(arr2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5438b6c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1    2\n",
      "3    2\n",
      "2    1\n",
      "1    3\n",
      "3    1\n",
      "2    1\n",
      "1    1\n",
      "2    1\n",
      "3    2\n",
      "3    1\n",
      "dtype: int32\n"
     ]
    }
   ],
   "source": [
    "arr3=pd.Series(arr1,arr2)\n",
    "print(arr3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5d789d0e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3, 5, 3, 4, 4, 3, 2, 3, 5, 4])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.add(arr1,arr2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "382926dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 6, 2, 3, 3, 2, 1, 2, 6, 3])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.multiply(arr1,arr2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7f427553",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2.        , 0.66666667, 0.5       , 3.        , 0.33333333,\n",
       "       0.5       , 1.        , 0.5       , 0.66666667, 0.33333333])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.divide(arr1,arr2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "45c61a98",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1, -1, -1,  2, -2, -1,  0, -1, -1, -2])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.subtract(arr1,arr2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57e427be",
   "metadata": {},
   "source": [
    "## 3a. you have 6 days, create a dataframe using a list of days as the column, and also a list of what you did during those days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "41456cad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    days     activity\n",
      "0  day 1         game\n",
      "1  day 2        clean\n",
      "2  day 3         camp\n",
      "3  day 4     work out\n",
      "4  day 5         cook\n",
      "5  day 6  photography\n"
     ]
    }
   ],
   "source": [
    "days=[\"day 1\",\"day 2\",\"day 3\",\"day 4\",\"day 5\",\"day 6\"]\n",
    "activity=[\"game\",\"clean\",\"camp\",\"work out\" ,\"cook\", \"photography\"]\n",
    "activities=list(zip(days,activity))\n",
    "df= pd.DataFrame(activities,columns=[\"days\",\"activity\"])\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4501a891",
   "metadata": {},
   "source": [
    "## 4a. create a csv file to show what maximum of 10 persons like and dislikes, with a dataset including the following criterias, a. name b. gender c. age d. country e. likes f. dislikes\n",
    "\n",
    "## hence your likes and dislikes should include random text such as a. football b. singing c. dancing d. coding\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "091ff407",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Name  Gender  Age    Country    Likes Dislikes\n",
      "0   Grace  female   19       Togo  fotball   coding\n",
      "1   Helen  female   39   Tanzania  singing  fotball\n",
      "2  Elijah    male   21      Niger  fotball  dancing\n",
      "3   Perpe  female   19  Mdagascar  fotball  singing\n",
      "4    Akin    male   24    Nigeria  dancing  singing\n",
      "5   Amina  female   17    Algeria   coding  singing\n",
      "6   Angel  female   19    Senegal  fotball   coding\n",
      "7  Adonai    male   29      Ghana   coding  dancing\n",
      "8   Sandy  female   20    Nigeria  singing   coding\n"
     ]
    }
   ],
   "source": [
    "project= pd.read_csv(\"project.csv\")\n",
    "print(project)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "160121a7",
   "metadata": {},
   "source": [
    "## 4b. create a dataframe with this data using pandas 4c. analyse the dataset with pandas by filtering the data by people who like just football 4d. repeat the process by filtering the people who dislike football as well 4e. print out a nice statement dynamically with python as follows with all the person that like and dislikes football eg. 'Precious likes football', 'James dislikes football'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "95c2fc3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Name  Gender  Age    Country    Likes Dislikes\n",
      "0   Grace  female   19       Togo  fotball   coding\n",
      "1   Helen  female   39   Tanzania  singing  fotball\n",
      "2  Elijah    male   21      Niger  fotball  dancing\n",
      "3   Perpe  female   19  Mdagascar  fotball  singing\n",
      "4    Akin    male   24    Nigeria  dancing  singing\n",
      "5   Amina  female   17    Algeria   coding  singing\n",
      "6   Angel  female   19    Senegal  fotball   coding\n",
      "7  Adonai    male   29      Ghana   coding  dancing\n",
      "8   Sandy  female   20    Nigeria  singing   coding\n"
     ]
    }
   ],
   "source": [
    "df2=pd.DataFrame(project)\n",
    "print(df2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "050f4455",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty DataFrame\n",
      "Columns: [Name, Gender, Age, Country, Likes, Dislikes]\n",
      "Index: []\n",
      "Empty DataFrame\n",
      "Columns: []\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "lovers=df2.query(\"Likes=='football'\")\n",
    "print(lovers)\n",
    "football_lovers=lovers.filter(like=\"football\")\n",
    "print(football_lovers)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "070f858f",
   "metadata": {},
   "source": [
    "## Apperantely given the data structure below, an error was found, the coutries are supposed to be ranked alphabetically by thier keys. as the values of each countries are ordered alphabetically.\n",
    "## a. your task is to create a dataframe with this dictionary. NOTE: DO NOT MODIFY THE DICTIONARY b. correctly re-arrange the keys alphabetically in their correct irder\n",
    "\n",
    "## countries = { 'third': ['America', 'Australia'], 'first': ['Italy', 'India'], 'second': ['Nigeria', 'New Zealand'] }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d7f8cd93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       third  first       second\n",
      "0    America  Italy      Nigeria\n",
      "1  Australia  India  New Zealand\n"
     ]
    }
   ],
   "source": [
    "countries = { 'third': ['America', 'Australia'], 'first': ['Italy', 'India'], 'second': ['Nigeria', 'New Zealand'] }\n",
    "df3=pd.DataFrame(countries)\n",
    "print(df3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "8b96ae80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       first second       third \n",
      "0    America  Italy      Nigeria\n",
      "1  Australia  India  New Zealand\n"
     ]
    }
   ],
   "source": [
    "df3.columns = ['first', 'second', 'third ']\n",
    "print(df3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dc83fc1",
   "metadata": {},
   "source": [
    "## 6 create a dataframe showing the scores and average score for jessica, bright and greatman in the following subjects, Maths, English and Physics. you are to use the exact procedures below to achieve this\n",
    "## a. the scores and average scores for each subject should be between 50 and 100 b. this scores are to be generated with numpy c. clearly display the subject on the correct column and the index using the names of the 3 student d. assuming a new student came on board, create a fresh dataframe for this student by name bob using the same process as follows by jessica, bright and greatman e. add these two dataframes together, NOTE: bob should come last d. sort these dataframe by the average score f. group this dataset by student who are above and below the average score of 60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "146ddefd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          maths  english  physics\n",
      "jessica      79       99       86\n",
      "bright       67       83       87\n",
      "greatman     70       62       61\n",
      "\n",
      "          maths  english  physics\n",
      "jessica      79       99       86\n",
      "bright       67       83       87\n",
      "greatman     70       62       61\n",
      "0            53       55       92\n"
     ]
    }
   ],
   "source": [
    "subjects ={\"maths\":np.random.randint(50,100,3),\n",
    "\"english\":np.random.randint(50,100,3),\n",
    "\"physics\":np.random.randint(50,100,3)}\n",
    "df6=pd.DataFrame(subjects,columns=(\"maths\",\"english\",\"physics\"),index=(\"jessica\",\"bright\",\"greatman\"))\n",
    "print(df6)\n",
    "subjects ={\"maths\":np.random.randint(50,100,1),\n",
    "\"english\":np.random.randint(50,100,1),\n",
    "\"physics\":np.random.randint(50,100,1)}\n",
    "df7=pd.DataFrame(subjects,columns=(\"maths\",\"english\",\"physics\"))\n",
    "df8=[df6,df7]\n",
    "combined_df=pd.concat(df8)\n",
    "print('')\n",
    "print(combined_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e28e2e9",
   "metadata": {},
   "source": [
    "## TASK\n",
    "## a. read this dataset using pandas\n",
    "## b. we dont care about the extraction_day and extraction_time, do not display this in the dataframe\n",
    "## NOTE: DO NOT MODIFY THE DATASET FROM THE CSV FILE\n",
    "## c. check the memory usage of this dataset, reduce the bandwidth in any possible way you can\n",
    "## d. display the first five and last five data in the dataframe\n",
    "## e. randomly display some part of the data in the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "db1d8819",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'Assignment/Numpy-pandas-matplotlib-course-files/diets.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_10180\\3324389045.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdiet\u001b[0m \u001b[1;33m=\u001b[0m\u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Assignment/Numpy-pandas-matplotlib-course-files/diets.csv\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\util\\_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    309\u001b[0m                     \u001b[0mstacklevel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mstacklevel\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    310\u001b[0m                 )\n\u001b[1;32m--> 311\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    312\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    313\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers\\readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[0;32m    676\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    677\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 678\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    679\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    680\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers\\readers.py\u001b[0m in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    573\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    574\u001b[0m     \u001b[1;31m# Create the parser.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 575\u001b[1;33m     \u001b[0mparser\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    576\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    577\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers\\readers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m    930\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    931\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhandles\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mIOHandles\u001b[0m \u001b[1;33m|\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 932\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    933\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    934\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers\\readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[1;34m(self, f, engine)\u001b[0m\n\u001b[0;32m   1214\u001b[0m             \u001b[1;31m# \"Union[str, PathLike[str], ReadCsvBuffer[bytes], ReadCsvBuffer[str]]\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1215\u001b[0m             \u001b[1;31m# , \"str\", \"bool\", \"Any\", \"Any\", \"Any\", \"Any\", \"Any\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1216\u001b[1;33m             self.handles = get_handle(  # type: ignore[call-overload]\n\u001b[0m\u001b[0;32m   1217\u001b[0m                 \u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1218\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\io\\common.py\u001b[0m in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    784\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mioargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mencoding\u001b[0m \u001b[1;32mand\u001b[0m \u001b[1;34m\"b\"\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mioargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    785\u001b[0m             \u001b[1;31m# Encoding\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 786\u001b[1;33m             handle = open(\n\u001b[0m\u001b[0;32m    787\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    788\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'Assignment/Numpy-pandas-matplotlib-course-files/diets.csv'"
     ]
    }
   ],
   "source": [
    "diet =pd.read_csv(\"Assignment/Numpy-pandas-matplotlib-course-files/diets.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6ee65d6",
   "metadata": {},
   "source": [
    "## Instructions Your tasks are to do the following:\n",
    "\n",
    "## Before beginning the analysis, you have two datasets combine them together to create one dataframe\n",
    "\n",
    "## check the data for any mouse ID with duplicate time points and remove any data associated with that mouse ID."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1ff70e04",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '.../../Mouse_metadate.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_10180\\2085853649.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmouse\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\".../../Mouse_metadate.csv\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mstudy_results\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"../../study_results.csv\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\util\\_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    309\u001b[0m                     \u001b[0mstacklevel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mstacklevel\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    310\u001b[0m                 )\n\u001b[1;32m--> 311\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    312\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    313\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers\\readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[0;32m    676\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    677\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 678\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    679\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    680\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers\\readers.py\u001b[0m in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    573\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    574\u001b[0m     \u001b[1;31m# Create the parser.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 575\u001b[1;33m     \u001b[0mparser\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    576\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    577\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers\\readers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m    930\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    931\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhandles\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mIOHandles\u001b[0m \u001b[1;33m|\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 932\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    933\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    934\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers\\readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[1;34m(self, f, engine)\u001b[0m\n\u001b[0;32m   1214\u001b[0m             \u001b[1;31m# \"Union[str, PathLike[str], ReadCsvBuffer[bytes], ReadCsvBuffer[str]]\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1215\u001b[0m             \u001b[1;31m# , \"str\", \"bool\", \"Any\", \"Any\", \"Any\", \"Any\", \"Any\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1216\u001b[1;33m             self.handles = get_handle(  # type: ignore[call-overload]\n\u001b[0m\u001b[0;32m   1217\u001b[0m                 \u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1218\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\io\\common.py\u001b[0m in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    784\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mioargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mencoding\u001b[0m \u001b[1;32mand\u001b[0m \u001b[1;34m\"b\"\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mioargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    785\u001b[0m             \u001b[1;31m# Encoding\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 786\u001b[1;33m             handle = open(\n\u001b[0m\u001b[0;32m    787\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    788\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '.../../Mouse_metadate.csv'"
     ]
    }
   ],
   "source": [
    "mouse=pd.read_csv(\".../../Mouse_metadate.csv\")\n",
    "study_results=pd.read_csv(\"../../study_results.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "583193c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Jessicah\\Desktop\\Assignment\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "cd=os.getcwd()\n",
    "print(cd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66c24f3c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
